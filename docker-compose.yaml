services:
  spark-master:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - AWS_REGION=us-east-1
    ports:
      - "8180:8080"
      - "7077:7077"
    volumes:
      - spark-data:/bitnami
      - ./datasets:/app/datasets
      - ./spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf

  spark-worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=12G
      - SPARK_WORKER_CORES=6
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - AWS_REGION=us-east-1
    depends_on:
      - spark-master
    volumes:
      - spark-data:/bitnami
      - ./datasets:/app/datasets
      - ./spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf

  python-dev:

    container_name: python-dev
    build:
      context: .
      dockerfile: Dockerfile.python-dev
    volumes:
      # - ./:/app
      - ./src:/app/src
      - ./datasets:/app/datasets
    working_dir: /app
    command: tail -f /dev/null
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - PYSPARK_PYTHON=python3
      - PYSPARK_DRIVER_PYTHON=python3
    ports:
      - "4040:4040" # Spark UI port
    depends_on:
      - spark-master

  java-dev:

    build:
      context: .
      dockerfile: Dockerfile.java-dev
    container_name: java-dev
    volumes:
      - ./:/app
      # - ./src/java:/app/src
      # - ./tests/java:/app/tests
      # - ./datasets:/app/datasets
    working_dir: /app
    command: tail -f /dev/null
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    depends_on:
      - spark-master

  scala-dev:
    image: hseeberger/scala-sbt:11.0.2-oraclelinux7_1.3.5_2.12.10
    container_name: scala-dev
    volumes:
      - ./src/scala:/app/src
      - ./tests/scala:/app/tests
      - ./datasets:/app/datasets
    working_dir: /app
    command: tail -f /dev/null
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    depends_on:
      - spark-master

volumes:
  spark-data:
  datasets:


networks:
  default:
    name: roadrunner-network
    external: true
